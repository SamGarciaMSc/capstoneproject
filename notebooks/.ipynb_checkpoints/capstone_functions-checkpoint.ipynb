{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8537020",
   "metadata": {},
   "source": [
    "Notebook to hold all functions for capstone project.\n",
    "\n",
    "Sources are referenced in codeblock comments at the top of any functions that have been taken from somewhere online."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4d616816",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import plot_confusion_matrix, confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963a135e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaler_w_column_names_tags(df_to_scale, scaler_type, tags='yes'):\n",
    "    \n",
    "    # instantiate scaler\n",
    "    scaler = scaler_type()\n",
    "\n",
    "    scaled_df = scaler.fit_transform(df_to_scale.drop('genre_group', axis=1))\n",
    "\n",
    "    if tags == 'yes':\n",
    "    # GET BACK GENRE TAGS\n",
    "        scaled_df = pd.DataFrame(scaled_df)\n",
    "        scaled_df['genre_group'] = df_to_scale['genre_group']\n",
    "    pass\n",
    "\n",
    "    # PUT BACK COLUMN NAMES\n",
    "    old_colnames = list(scaled_df.columns)\n",
    "    new_colnames= list(df_to_scale.columns)\n",
    "    rename_dict = {a:b for a,b in zip(old_colnames,new_colnames)}\n",
    "    scaled_df.rename(columns=rename_dict, inplace=True)\n",
    "    scaled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4733ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaler_w_column_names(df_to_scale, scaler_type):\n",
    "    \n",
    "    # instantiate and implementscaler\n",
    "    scaler = scaler_type\n",
    "    scaled_df = scaler.fit_transform(df_to_scale)\n",
    "\n",
    "    scaled_df = pd.DataFrame(scaled_df)\n",
    "    \n",
    "    # PUT BACK COLUMN NAMES\n",
    "    old_colnames = list(scaled_df.columns)\n",
    "    new_colnames= list(df_to_scale.columns)\n",
    "    rename_dict = {a:b for a,b in zip(old_colnames,new_colnames)}\n",
    "    scaled_df.rename(columns=rename_dict, inplace=True)\n",
    "    scaled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab9e10ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans_k(scaled_df):\n",
    "    # run a few k values to plot the inertia and silhouette scores\n",
    "    # we have 13 features so let's run 2 to 13\n",
    "    k_range = np.arange(2, scaled_df.shape[1]+1)\n",
    "    inertia_list = []\n",
    "    silhouette_score_list = []\n",
    "\n",
    "    for k in k_range:\n",
    "        #Instantiate\n",
    "        KMeans_model = KMeans(n_clusters = k)\n",
    "        # Fit KMeans\n",
    "        y_labels = KMeans_model.fit_predict(scaled_df)\n",
    "        # Save the intertia and silhouette scores\n",
    "        inertia_list.append(KMeans_model.inertia_)\n",
    "        silhouette_score_list.append(silhouette_score(scaled_df, y_labels))\n",
    "\n",
    "        print(f'Computing scores for k = {k}') #to see that the model is running and hasn't crashed\n",
    "    \n",
    "    # plot silhouette scores\n",
    "    plt.figure()\n",
    "    plt.plot(k_range, silhouette_score_list, marker = 'o')\n",
    "    plt.xlabel('K')\n",
    "    plt.ylabel('Silhouette Score')\n",
    "    plt.title('Silhouette by No. of Clusters')\n",
    "    plt.xticks(k_range)\n",
    "    plt.show()\n",
    "    \n",
    "    # plot inertia scores\n",
    "    plt.figure()\n",
    "    plt.plot(k_range, inertia_list, marker=\"o\")\n",
    "    plt.xlabel('Number of Clusters')\n",
    "    plt.ylabel('Inertia')\n",
    "    plt.title('Inertia by No. of Clusters')\n",
    "    plt.xticks(k_range)\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9b11b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans_model(scaled_df, k):\n",
    "    # run kmeans model for chosen number of clusters\n",
    "    KMeans_model = KMeans(n_clusters = k)\n",
    "    kmeans_y_labels = KMeans_model.fit_predict(scaled_df)\n",
    "\n",
    "    # Let's add our labels to the dataset so we can colour our clusters on graphs. \n",
    "    kmeans_df = scaled_df.copy()\n",
    "    kmeans_df['kmeans_labels'] = kmeans_y_labels\n",
    "    \n",
    "    # create sample for t-sne\n",
    "    sample = kmeans_df.sample(frac=0.4, random_state = 1)\n",
    "\n",
    "    # Instantiate t-SNE\n",
    "    tsne = TSNE(n_components = 3, random_state = 1, verbose = 1)\n",
    "    # Fit_Transform t-SNE\n",
    "    tsne_data = tsne.fit_transform(sample)\n",
    "    \n",
    "    # create tSNE dataframe\n",
    "    tsne_df = pd.DataFrame(tsne_data, columns = [f'tSNE D{i+1}' for i in range(tsne_data.shape[1])])\n",
    "    \n",
    "    # ADD CLUSTER LABELS\n",
    "    tsne_df['kmeans_labels'] = sample['kmeans_labels'].values\n",
    "    \n",
    "    # visualise\n",
    "    sns.pairplot(tsne_df, hue = 'kmeans_labels', plot_kws = {'alpha': 0.5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57c0aa54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dbscan_epsilon(scaled_df, eps_start, eps_end, counter):\n",
    "    # try a range of epsilons\n",
    "    eps_range = np.arange(eps_start,eps_end,counter)\n",
    "    num_clusters = []\n",
    "    silhouette_scores = []\n",
    "    \n",
    "    from tempfile import mkdtemp\n",
    "    cachedir = mkdtemp()\n",
    "\n",
    "    for epsilon in eps_range:\n",
    "        DBS_model = DBSCAN(eps = epsilon, min_samples = 5)\n",
    "\n",
    "        y_labels = DBS_model.fit_predict(scaled_df)\n",
    "\n",
    "        silhouette = silhouette_score(scaled_df, y_labels)\n",
    "        silhouette_scores.append(silhouette)\n",
    "\n",
    "        n_clusters = len(np.unique(y_labels[y_labels != -1]))\n",
    "\n",
    "        num_clusters.append(n_clusters)\n",
    "\n",
    "        print(f'eps = {round(epsilon, 2)}, --- n_clusters: {n_clusters} --- silhouette: {silhouette}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955fd329",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dbscan_model(scaled_df, e):\n",
    "    DBS_model = DBSCAN(eps = e, min_samples = 5)\n",
    "    dbscan_y_labels = DBS_model.fit_predict(scaled_df)\n",
    "\n",
    "    # Let's add our labels to the dataset so we can colour our clusters on graphs. \n",
    "    DBS_df = scaled_df.copy()\n",
    "    DBS_df['dbscan_labels'] = dbscan_y_labels\n",
    "\n",
    "    sample = DBS_df.sample(frac=0.4, random_state = 1)\n",
    "\n",
    "    # Instantiate t-SNE\n",
    "    DB_tsne = TSNE(n_components = 3, random_state = 1, verbose = 1)\n",
    "    \n",
    "    # Fit_Transform t-SNE\n",
    "    DB_tsne_data = DB_tsne.fit_transform(sample.drop('dbscan_labels', axis = 1))\n",
    "\n",
    "    # create tSNE dataframe\n",
    "    DB_tsne_df = pd.DataFrame(DB_tsne_data, columns = [f'tSNE D{i+1}' for i in range(DB_tsne_data.shape[1])])\n",
    "    \n",
    "    # ADD CLUSTER LABELS   \n",
    "    DB_tsne_df['dbscan_labels'] = sample['dbscan_labels'].values\n",
    "\n",
    "    # visualise\n",
    "    sns.pairplot(DB_tsne_df, hue = 'dbscan_labels', plot_kws={'alpha':0.5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "335cc92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_train_test(model, X_train, y_train):\n",
    "    \n",
    "    # get the probability for each point in the train set.\n",
    "    y_proba_train = model.predict_proba(X_train)[:,1]\n",
    "\n",
    "    # Compute ROC curve and AUC for for the one class\n",
    "    fprs_train, tprs_train, thresholds_train = roc_curve(y_train, y_proba_train)\n",
    "    roc_auc_train = roc_auc_score(y_train, y_proba_train)\n",
    "\n",
    "    # Plot the ROC curve.\n",
    "    plt.figure()\n",
    "    plt.plot(fprs_train, tprs_train, color='darkorange', lw=2, label='train')\n",
    "    plt.plot(fprs, tprs, lw=2, label='test')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC and AUC')\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.show()\n",
    "    print(f\"Test AUC score: {roc_auc}\")\n",
    "    print(f\"Train AUC score: {roc_auc_train}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae088e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_importance(fittedgrid):\n",
    "    # calculate feature importances\n",
    "    importances = fittedgrid.best_estimator_.steps[len(fittedgrid.best_estimator_.steps)-1][1].feature_importances_\n",
    "\n",
    "    forest_importances = pd.Series(importances, index=X_train.columns)\n",
    "    std = np.std([importances for tree in fittedgrid.best_estimator_], axis=0)\n",
    "\n",
    "    # plot feature importances\n",
    "    fig, ax = plt.subplots()\n",
    "    forest_importances.plot.bar(yerr=std, ax=ax)\n",
    "    ax.set_title(\"Feature importances using MDI\")\n",
    "    ax.set_ylabel(\"Mean decrease in impurity\")\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "24a614dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/vinyluis/Articles/blob/main/ROC%20Curve%20and%20ROC%20AUC/ROC%20Curve%20-%20Multiclass.ipynb\n",
    "def calculate_tpr_fpr(y_real, y_pred):\n",
    "    '''\n",
    "    Calculates the True Positive Rate (tpr) and the True Negative Rate (fpr) based on real and predicted observations\n",
    "    \n",
    "    Args:\n",
    "        y_real: The list or series with the real classes\n",
    "        y_pred: The list or series with the predicted classes\n",
    "        \n",
    "    Returns:\n",
    "        tpr: The True Positive Rate of the classifier\n",
    "        fpr: The False Positive Rate of the classifier\n",
    "    '''\n",
    "    \n",
    "    # Calculates the confusion matrix and recover each element\n",
    "    cm = confusion_matrix(y_real, y_pred)\n",
    "    TN = cm[0, 0]\n",
    "    FP = cm[0, 1]\n",
    "    FN = cm[1, 0]\n",
    "    TP = cm[1, 1]\n",
    "    \n",
    "    # Calculates tpr and fpr\n",
    "    tpr =  TP/(TP + FN) # sensitivity - true positive rate\n",
    "    fpr = 1 - TN/(TN+FP) # 1-specificity - false positive rate\n",
    "    \n",
    "    return tpr, fpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "db0bb9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/vinyluis/Articles/blob/main/ROC%20Curve%20and%20ROC%20AUC/ROC%20Curve%20-%20Multiclass.ipynb\n",
    "def get_all_roc_coordinates(y_real, y_proba):\n",
    "    '''\n",
    "    Calculates all the ROC Curve coordinates (tpr and fpr) by considering each point as a treshold for the predicion of the class.\n",
    "    \n",
    "    Args:\n",
    "        y_real: The list or series with the real classes.\n",
    "        y_proba: The array with the probabilities for each class, obtained by using the `.predict_proba()` method.\n",
    "        \n",
    "    Returns:\n",
    "        tpr_list: The list of TPRs representing each threshold.\n",
    "        fpr_list: The list of FPRs representing each threshold.\n",
    "    '''\n",
    "    tpr_list = [0]\n",
    "    fpr_list = [0]\n",
    "    for i in range(len(y_proba)):\n",
    "        threshold = y_proba[i]\n",
    "        y_pred = y_proba >= threshold\n",
    "        tpr, fpr = calculate_tpr_fpr(y_real, y_pred)\n",
    "        tpr_list.append(tpr)\n",
    "        fpr_list.append(fpr)\n",
    "    return tpr_list, fpr_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "69d8b669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/vinyluis/Articles/blob/main/ROC%20Curve%20and%20ROC%20AUC/ROC%20Curve%20-%20Multiclass.ipynb\n",
    "def plot_roc_curve(tpr, fpr, scatter = True, ax = None):\n",
    "    '''\n",
    "    Plots the ROC Curve by using the list of coordinates (tpr and fpr).\n",
    "    \n",
    "    Args:\n",
    "        tpr: The list of TPRs representing each coordinate.\n",
    "        fpr: The list of FPRs representing each coordinate.\n",
    "        scatter: When True, the points used on the calculation will be plotted with the line (default = True).\n",
    "    '''\n",
    "    if ax == None:\n",
    "        plt.figure(figsize = (5, 5))\n",
    "        ax = plt.axes()\n",
    "    \n",
    "    if scatter:\n",
    "        sns.scatterplot(x = fpr, y = tpr, ax = ax)\n",
    "    sns.lineplot(x = fpr, y = tpr, ax = ax)\n",
    "    sns.lineplot(x = [0, 1], y = [0, 1], color = 'green', ax = ax)\n",
    "    plt.xlim(-0.05, 1.05)\n",
    "    plt.ylim(-0.05, 1.05)\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae96368",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone",
   "language": "python",
   "name": "capstone"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
